; A QTM specification that solves Deutsch's problem.
; This specification implements an oracle for f(x) = x
;
; M1: put input x into superposition
0,0,1,1,1,0.7071067811865476
0,0,0,1,1,0.7071067811865476
0,1,1,1,1,0.7071067811865476
0,1,0,1,1,-0.7071067811865476

; M1: put input y into superposition
1,0,0,2,-1,0.7071067811865476
1,0,1,2,-1,0.7071067811865476
1,1,0,2,-1,0.7071067811865476
1,1,1,2,-1,-0.7071067811865476

; M0: read input x and advance to y.
2,0,0,3,1,1
2,1,1,4,1,1

; M0: f(x) = x, compute x is 0, we are reading y for y xor f(x)
3,0,0,5,-1,1
3,1,1,5,-1,1

; M0: f(x) = x, compute x is 1, we are reading y for y xor f(x)
4,0,1,5,-1,1
4,1,0,5,-1,1

; M1: collapse the super position on x
5,0,0,6,0,0.7071067811865476
5,0,1,6,0,0.7071067811865476
5,1,0,6,0,0.7071067811865476
5,1,1,6,0,-0.7071067811865476

; halting state
6,0,0,6,0,1
6,1,1,6,0,1
6,2,2,6,0,1

